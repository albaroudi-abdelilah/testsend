<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Detective</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 20px;
            display: flex;
            flex-direction: column;
            align-items: center;
            background: #f0f2f5;
        }
        .container {
            max-width: 800px;
            width: 100%;
        }
        .video-container {
            position: relative;
            margin: 20px 0;
        }
        #video, #canvas {
            width: 100%;
            max-width: 640px;
            margin: auto;
            display: block;
        }
        #canvas {
            position: absolute;
            top: 0;
            left: 50%;
            transform: translateX(-50%);
        }
        .controls {
            margin: 20px 0;
            text-align: center;
        }
        .status {
            text-align: center;
            margin: 10px 0;
            padding: 10px;
            border-radius: 4px;
        }
        .status.success {
            background-color: #d4edda;
            color: #155724;
        }
        .status.error {
            background-color: #f8d7da;
            color: #721c24;
        }
        .button {
            background: #4CAF50;
            color: white;
            border: none;
            padding: 10px 20px;
            border-radius: 4px;
            cursor: pointer;
            margin: 5px;
        }
        .button:disabled {
            background: #cccccc;
            cursor: not-allowed;
        }
        #targetImage {
            max-width: 200px;
            margin: 10px auto;
            display: block;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1> Detective</h1>
        <div class="controls">
            <input type="file" id="imageUpload" accept="image/*" style="display: none">
            <button class="button" onclick="document.getElementById('imageUpload').click()">Upload Target Face</button>
        </div>
        <img id="targetImage" style="display: none">
        <div class="video-container">
            <video id="video" autoplay muted></video>
            <canvas id="canvas"></canvas>
        </div>
        <div id="status" class="status"></div>
    </div>
    <script src="https://cdn.jsdelivr.net/npm/face-api.js"></script>
    <script>
        let video;
        let canvas;
        let targetDescriptor = null;
        const STATUS = document.getElementById('status');

        // Load face-api models from your server
        async function loadModels() {
            STATUS.textContent = 'Loading models...';
            try {
                await Promise.all([
                    faceapi.nets.faceRecognitionNet.loadFromUri('/weights'),
                    faceapi.nets.faceLandmark68Net.loadFromUri('/weights'),
                    faceapi.nets.ssdMobilenetv1.loadFromUri('/weights')
                ]);
                STATUS.textContent = 'Models loaded! You can now upload a target image.';
                STATUS.className = 'status success';
                startVideo();
            } catch (error) {
                STATUS.textContent = 'Error loading models. Please refresh the page.';
                STATUS.className = 'status error';
                console.error('Error loading models:', error);
            }
        }

        // Start video stream
        async function startVideo() {
            video = document.getElementById('video');
            canvas = document.getElementById('canvas');

            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video.srcObject = stream;
            } catch (error) {
                STATUS.textContent = 'Error accessing camera. Please ensure camera permissions are granted.';
                STATUS.className = 'status error';
                console.error('Error accessing camera:', error);
            }
        }

        // Handle target image upload
        document.getElementById('imageUpload').addEventListener('change', async function(event) {
            const file = event.target.files[0];
            if (!file) return;

            const img = document.getElementById('targetImage');
            img.src = URL.createObjectURL(file);
            img.style.display = 'block';

            STATUS.textContent = 'Processing target face...';
            STATUS.className = '';

            img.onload = async () => {
                try {
                    const detection = await faceapi.detectSingleFace(img)
                        .withFaceLandmarks()
                        .withFaceDescriptor();

                    if (detection) {
                        targetDescriptor = detection.descriptor;
                        STATUS.textContent = 'Target face processed! Now scanning for matches...';
                        STATUS.className = 'status success';
                        startFaceDetection();
                    } else {
                        STATUS.textContent = 'No face detected in the uploaded image. Please try another image.';
                        STATUS.className = 'status error';
                    }
                } catch (error) {
                    STATUS.textContent = 'Error processing target face. Please try again.';
                    STATUS.className = 'status error';
                    console.error('Error processing target face:', error);
                }
            };
        });

        // Main face detection loop
        async function startFaceDetection() {
            if (!targetDescriptor) return;

            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;

            const detectFaces = async () => {
                const detections = await faceapi.detectAllFaces(video)
                    .withFaceLandmarks()
                    .withFaceDescriptors();

                const ctx = canvas.getContext('2d');
                ctx.clearRect(0, 0, canvas.width, canvas.height);

                detections.forEach(detection => {
                    const distance = faceapi.euclideanDistance(targetDescriptor, detection.descriptor);
                    const box = detection.detection.box;

                    ctx.lineWidth = 2;
                    if (distance < 0.6) {
                        ctx.strokeStyle = '#00ff00'; // Green for match
                        ctx.strokeRect(box.x, box.y, box.width, box.height);
                    } else {
                        ctx.strokeStyle = '#ff0000'; // Red for non-match
                        ctx.strokeRect(box.x, box.y, box.width, box.height);
                    }
                });

                requestAnimationFrame(detectFaces);
            };

            detectFaces();
        }

        // Start the application
        document.addEventListener('DOMContentLoaded', loadModels);
    </script>
</body>
</html>
